<!DOCTYPE html>
<html>
  <head>
    <link rel="icon" type="image/png"
     href="resources/images/favicon.ico" />
    <script type="text/javascript" src="resources/js/jquery.js"></script>
    <script type="text/javascript" src="resources/js/quiz-1.js"></script>
    <link href="https://fonts.googleapis.com/css?family=Hind" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="resources/css/style.css">
    <meta charset="utf-8">
    <title>Markov Chains</title>
  </head>
  <body>
    <!-- <nav>
    In case I want to add a navigation bar for more webpages
    </nav> -->
    <center><div id="title">
      <h1 id="main-title">Markov Chains</h1>
    </div></center>
    <p id="group-members"> Text by Esther Cao, Ayush Gupta, and Vivian Young<br />Design by Vivian Young </p>
    <nav class="floating-menu">
      <center><h2>Menu</h2></center>
      <a href="#history">History</a></li>
      <a href="#definition">Markov Chains</a>
      <!-- <a href="#properties">Properties</a> -->
      <a href=#transition-matrix>Transition Matrix</a>
      <!-- <a href=#transition-properties>Properties of Transition Matrices</a> -->
      <a href="#state-vectors">State/Probability Vectors</a>
      <!-- <a href="#state-vectors-properties">Properties of State Vectors</a> -->
      <a href="#regular">Regular Transition Matrix</a>
      <a href="#non-regular">Non-Regular Transition Matrix</a>
      <a href="#steady-state">Steady-State Vectors</a>
      <a href="#eigen">Eigenvectors and Eigenvalues</a>
      <a href="#second-iteration"Second Iteration</a>
      <a href="#absorbing">Absorbing Markov Chains</a>
      <a href="#applications">Applications</a>
      <a href="#quiz">Quiz</a>
      <a href=#repl>Markov Chains- Ruby Code</a>
      <a href=#sources>Sources</a>
    </nav>
    <div id="quiz-link">
      <p>
        <center>
          Test your knowledge of Markov Chains with this <a href="#quiz">quiz</a>!
        </center>
      </p>
    </div>
    <div class="section-title" id="history">
      <h3>History</h3>
      <p>Markov chains are named after their creator, Andrey Markov. They are mathematical
        systems that anticipate future events from a current state. Markov initially designed Markov chains in order
        to analyze the frequencies of vowels and consonants in the novel<em> Eugene Onegin</em>.
        </p>
    </div>
    <div class="section-title" id="definition"><!--What is a Markov Chain?-->
      <h3>What is a Markov Chain?</center> </h3>
      <img src="resources/images/chain.png" align="left">
      <p>Markov Chains have a set of distinct states. They can be used to interpret and understand intricate, real-life processes.
      A fundamental aspect of Markov chains is its tendency to anticipate future states based on only its previous state.
      In other words, the outcomes of trials in the Markov Chains are dependent only on the outcome of the previous state. There can only be one state at a time. Each
      state gives a probability distribution of different events occuring. Because of this, more complex tasks are simplified and take into account a conditional probability
      instead of programs that involve countless of past scenarios.</p>
    </div>
    <div class="section-title" id="properties"><!--Properties of Markov Chains-->
      <h3>Properties of Markov Chains</center> </h3>
        <ul>
          <li>At any time, each object is at exactly one state</li>
          <li>Objects move between states according to transition probabilities (based on current state)</li>
          <li>Transition probabilities remain constant</li>
        </ul>
    </div>
    <div class="section-title" id="example"><!--Example of Markov Chain-->
      <h3>Example Problem</center> </h3>
      <p>
        A large city consumes solely Red Vines and Twizzlers. One of these candy companies wants to hold a larger share of the market and they conduct research to see which company is more successful after a disastrous FDA recall of Twizzlers and one month’s time. Currently, Red Vines owns 35% while Twizzlers owns 65% of the market share. These are some of the conclusions discovered after extensive research:
        P(R → R): probability of a customer staying with Red Vines in the month = 0.8
        P(R → T): probability of a customer switching from Red Vines to Twizzlers in the month = 0.2
        P(T → T): probability of a customer staying with Twizzlers in the month = 0.6
        P(T → R): probability of a customer switching from Twizzlers to Red Vines in the month = 0.4
        <br />
        <br />
        To solve this problem, we need to construct an initial state matrix and multiply it by a transition matrix (which we will talk about very soon) to determine the final market shares of the two companies.
      </p>
      <center>
        <img src="https://lh4.googleusercontent.com/CVanwA5W9HnFXdu3ycj5rij-O53EMwczo7X0KTKbKZ9AIKXT2GCgYc4Sd2pcgfXo9VQ2fE_GaI4IvtYqSZlw0Zip3YJkM23nFEDbZTsWzyfBHm_Rbk5oS-SUSV0rkPexeGbR4QkU">
      </center>
      <p>
        As you can see, the final state after one month is Red Vines owning 67% of the market share and Twizzlers owning 33%.
      </p>
    </div>
    <div class="section-title" id="transition-matrix"><!--What does a Transition Matrix do?-->
      <h3>Transition Matrix</center> </h3>
      <p>Transition matrices contain all transition probabilities from one state to another.  </p>
    </div>
    <div class="section-title" id="transition-properties"><!--Properties of a Transition Matrix-->
      <h3>Properties of a Transition Matrix</center> </h3>
      <ul>
        <li>Must be a square matrix</li>
        <li>Elements represent probabilies, so these values must be in the range [0,1]</li>
        <li>The sum of all elements in a row must be 1</li>
        <li>Named T or P</li>
      </ul>
    </div>
    <div class="section-title" id="state-vectors"><!--State/Probability Vectors-->
      <h3>State/Probability Vectors</center> </h3>
      <p>For a system with <em>n</em> states, the <strong>state vector</strong> of a Markov chain
      is a row or column vector q^k of n elements where q is the probability that the system is in the ith state after
      k trials.</p>
    </div>
    <div class="section-title" id="state-vectors-properties">
      <h3>Properties of State Vectors</h3>
      <ul>
        <li>Horizontal vector</li>
        <li>Same number of elements as states in the Markov chain</li>
        <li>Shows probability distribution of all states</li>
        <li>Sum of elements is 1</li>
        <li>Named q or x</li>
      </ul>
    </div>
    <div class="section-title" id="regular">
      <h3>Regular Transition Matrix</h3>
      <p>
        Transition matrices are considered <em>regular</em> if they contain all non-zero
        elements. These can be used to find steady-state or equilibrium vectors.
        <center><img src="resources/images/regular.PNG" Regular Transition Matrix/></center>
        <center>This matrix is regular because all of its elements are positive.</center>
      </p>
    </div>
    <div class="section-title" id="non-regular">
      <h3>Non-Regular Transition Matrix</h3>
      <p>
        Matrix A is not regular because any power of A still contains 0. Thus, no matrices of A contain
        all positive elements.
      </p>
      <center><img src="resources/images/nonregular.PNG" Non-Regular Transition Matrix/></center>
    </div>
    <div class="section-title" id="steady-state">
      <h3>Steady-State Vectors</h3>
      <p>
        After a large number of trials, the state vector remains constant. At this time, the
        Markov chain has reached a stable distribution. This is called the <em>steady-state vector</em>
        , also known as an <em>equilibrium vector</em>, and is represented by s or v. If A*p = A, then it is a steady-state vector.  <br>
        <strong>They are independent of the original probability distribution and remain constant no matter what.</strong>
      </p>
      <center><img src="resources/images/steady.PNG" Steady-state vector/></center>
    </div>
    <div class="section-title" id= "eigen">
      <h3>Eigenvectors and Eigenvalues</h3>

    </div>
    <div class="section-title" id="absorbing">
      <h3>Absorbing Markov Chains</h3>
      <p>
        When the probability of jumping from state A to state B is 0.5, the probability
        of staying at state A when it is already at state A is 1.
        This is called the absorbing state, since when it gets there, it gets "absorbed". At
        this point, it can no longer change to another state.
      </p>
    </div>


    <div class="section-title" id="quiz">
      <h3> Quiz </h3>
      <p class="question">1. Who was the creator of Markov Chains?</p>

      <ul class="answers">
        <input type="radio" name="q1" value="a" id="q1a"><label for="q1a">A. Anthony Markov</label><br/>
        <input type="radio" name="q1" value="b" id="q1b"><label for="q1b">B. Andrey Markov</label><br/>
        <input type="radio" name="q1" value="c" id="q1c"><label for="q1c">C. Antonio Markov</label><br/>
        <input type="radio" name="q1" value="d" id="q1d"><label for="q1d">D. Anna Markov</label><br/>
      </ul>


      <p class="question">2. What are Markov Chains?</p>

      <ul class="answers">
        <input type="radio" name="q2" value="a" id="q2a"><label for="q2a">A. A psychological phenomenon involving Andrew Markov and his fear of metal chains</label><br/>
        <input type="radio" name="q2" value="b" id="q2b"><label for="q2b">B. A scientific experiment done to prove Einstein's theory of relativity</label><br/>
        <input type="radio" name="q2" value="c" id="q2c"><label for="q2c">C. A mathematical model that anticipates future occurrances</label><br/>
        <input type="radio" name="q2" value="d" id="q2d"><label for="q2d">D. An old Russian recipe that is heavily guarded by the Kremlin</label><br/>
      </ul>

      <p class="question">3. True or False? Markov Chains are unique because its states depend on the outcomes of <em>all</em> previous states. </p>

      <ul class="answers">
        <input type="radio" name="q3" value="a" id="q3a"><label for="q3a">A. Not enough information</label><br/>
        <input type="radio" name="q3" value="b" id="q3b"><label for="q3b">B. 98</label><br/>
        <input type="radio" name="q3" value="c" id="q3c"><label for="q3c">C. True</label><br/>
        <input type="radio" name="q3" value="d" id="q3d"><label for="q3d">D. False</label><br/>
      </ul>

      <p class="question">4. What is one property of Markov Chains?</p>

      <ul class="answers">
        <input type="radio" name="q4" value="a" id="q4a"><label for="q4a">A. They can only be written using Russian letters</label><br/>
        <input type="radio" name="q4" value="b" id="q4b"><label for="q4b">B. Transition probabilities remain constant</label><br/>
        <input type="radio" name="q4" value="c" id="q4c"><label for="q4c">C. Each state is dependent on the state after it</label><br/>
        <input type="radio" name="q4" value="d" id="q4d"><label for="q4d">D. Markov Chains can only be run 2,893 times.</label><br/>
      </ul>

      <p class="question">5. What is a Transition Matrix?</p>

      <ul class="answers">
        <input type="radio" name="q5" value="a" id="q5a"><label for="q5a">A. A matrix containing all transition probabilities from one state to another</label><br/>
        <input type="radio" name="q5" value="b" id="q5b"><label for="q5b">B. A matrix containing the number of states in the Markov Chains </label><br/>
        <input type="radio" name="q5" value="c" id="q5c"><label for="q5c">C. A vector containing the coordinates of North Korea's capitol, Pyongyang.</label><br/>
        <input type="radio" name="q5" value="d" id="q5d"><label for="q5d">D. A matrix in which all numbers are zero. </label><br/>
      </ul>

      <p class="question">6. How do you know if a Transition Matrix is regular?</p>

      <ul class="answers">
        <input type="radio" name="q6" value="a" id="q6a"><label for="q6a">A. Its size is in between "mini" and "large"</label><br/>
        <input type="radio" name="q6" value="b" id="q6b"><label for="q6b">B. It contains all zero elements</label><br/>
        <input type="radio" name="q6" value="c" id="q6c"><label for="q6c">C. It contains all non-zero elements</label><br/>
        <input type="radio" name="q6" value="d" id="q6d"><label for="q6d">D. It is the first state of the Markov Chain</label><br/>
      </ul>

      <p class="question">7. True or False? The eigenvector is unchanged when its transition matrix is applied to it.</p>

      <ul class="answers">
        <input type="radio" name="q7" value="a" id="q7a"><label for="q7a">A. Always true because that is the definition</label><br/>
        <input type="radio" name="q7" value="b" id="q7b"><label for="q7b">B. False because of eigenvalues</label><br/>
        <input type="radio" name="q7" value="c" id="q7c"><label for="q7c">C. Sometimes because its direction changes minimally</label><br/>
        <input type="radio" name="q7" value="d" id="q7d"><label for="q7d">D. False because it always rotates 90 decrees clockwise</label><br/>
      </ul>

      <p class="question">8. Which of the following is the matrix equation to find the steady-state vector?</p>

      <ul class="answers">
        <input type="radio" name="q8" value="a" id="q8a"><label for="q8a">A. s(I - T) = 0</label><br/>
        <input type="radio" name="q8" value="b" id="q8b"><label for="q8b">B. T - 1 = s</label><br/>
        <input type="radio" name="q8" value="c" id="q8c"><label for="q8c">C. s(T - 1) = 0</label><br/>
        <input type="radio" name="q8" value="d" id="q8d"><label for="q8d">T(1 - s) = 0</label><br/>
      </ul>

      <p class="question">9. What would the state vector of an absorbing Markov chain (with 1 absorbing state) look like after infinite trials?</p>

      <ul class="answers">
        <input type="radio" name="q9" value="a" id="q9a"><label for="q9a">A. It is impossible to determine</label><br/>
        <input type="radio" name="q9" value="b" id="q9b"><label for="q9b">B. 1.0 for the absorbing state and 0.0 for others</label><br/>
        <input type="radio" name="q9" value="c" id="q9c"><label for="q9c">C. Between 0.8 and 0.9 for the absorbing state</label><br/>
        <input type="radio" name="q9" value="d" id="q9d"><label for="q9d">D. 0.0 for the absorbing state, others are even</label><br/>
      </ul>

      <p class="question">10. In what fields of study are Markov Chains used?</p>

      <ul class="answers">
        <input type="radio" name="q10" value="a" id="q10a"><label for="q10a">A. Chemistry</label><br/>
        <input type="radio" name="q10" value="b" id="q10b"><label for="q10b">B. Finance</label><br/>
        <input type="radio" name="q10" value="c" id="q10c"><label for="q10c">C. Ecology</label><br/>
        <input type="radio" name="q10" value="d" id="q10d"><label for="q10d">D. All of the above</label><br/>
      </ul>

      <br/>
    <div id="results">
        Check my answers!
    </div>

    <p>Note: Answers will not be shown until all questions are answered.</p>

    <div id="category1">
        <p>
          <strong>Question 1:</strong> Sorry, the correct answer is <strong>B</strong>.</p>
    </div>

    <div id="category2">
        <p>
          <strong>Question 2:</strong> Sorry, the correct answer is <strong>C</strong>.</p>
    </div>

    <div id="category3">
        <p>
          <strong>Question 3:</strong> Sorry, the correct answer is <strong>D</strong>.</p>
    </div>

    <div id="category4">
        <p>
          <strong>Question 4:</strong> Sorry, the correct answer is <strong>B</strong>.</p>
    </div>

    <div id="category5">
        <p>
          <strong>Question 5:</strong> Sorry, the correct answer is <strong>A</strong>.</p>
    </div>

    <div id="category6">
        <p>
          <strong>Question 6:</strong> Sorry, the correct answer is <strong>C</strong>.</p>
    </div>

    <div id="category7">
        <p>
          <strong>Question 7:</strong> Sorry, the correct answer is <strong>B</strong>.</p>
    </div>

    <div id="category8">
        <p>
          <strong>Question 8:</strong> Sorry, the correct answer is <strong>C</strong>.</p>
    </div>

    <div id="category9">
        <p>
          <strong>Question 9:</strong> Sorry, the correct answer is <strong>B</strong>.</p>
    </div>

    <div id="category10">
        <p>
          <strong>Question 10:</strong> Sorry, the correct answer is <strong>D</strong>.</p>
    </div>

    <div id="category11">
        <p>
          You answered them all right!</p>
    </div>
    </div>

    <div class="section-title" id="repl">
      <h3> Markov Chains - Ruby Code </h3>
      <p>This is a demonstration of the workings of Markov Chains, coded with the
        programming language, Ruby. <br>To run this program, press the <em>run</em> button. If you would like to play around with the program, scroll to the bottom and read the green comments for help.</p>
      <center><iframe frameborder="0" width="100%" height="500px" src="https://repl.it/GWqC/2"></iframe></center>
    </div>
    <div class="section-title" id="sources"><!--Sources-->
      <h3>Sources</h3>
        <a href="https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf">Click me</a><br>
        <a href="https://www.math.ucdavis.edu/~daddel/linear_algebra_appl/Applications/MarkovChain/MarkovChain_9_18/node1.html">Click me</a><br>
        <a href="https://www.scribd.com/document/338415365/DFAI-MARKOV-CHAINS-02-pdf">Click me</a>
        <a href="http://www.math.bas.bg/~jeni/Rebecca_Atherton.pdf">Click me </a>
    </div>




  </body>
</html>
