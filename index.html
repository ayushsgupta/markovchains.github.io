<!DOCTYPE html>
<html>
  <head>
    <link href="https://fonts.googleapis.com/css?family=Hind" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:300" rel="stylesheet">
    <link rel="stylesheet" type="text/css" href="resources/css/style.css">
    <meta charset="utf-8">
    <title>Markov Chains</title>
  </head>
  <body>
    <!-- <nav>
    In case I want to add a navigation bar for more webpages
    </nav> -->
    <center><div id="title">
      <h1 id="main-title">Markov Chains</h1>
    </div></center>
    <p id="group-members"> Text by Esther Cao, Ayush Gupta, and Vivian Young<br />Design by Vivian Young </p>
    <nav class="floating-menu">
      <center><h2>Menu</h2></center>
      <a href="#history">History</a></li>
      <a href="#definition">Markov Chains</a>
      <!-- <a href="#properties">Properties</a> -->
      <a href=#transition-matrix>Transition Matrix</a>
      <!-- <a href=#transition-properties>Properties of Transition Matrices</a> -->
      <a href="#state-vectors">State/Probability Vectors</a>
      <!-- <a href="#state-vectors-properties">Properties of State Vectors</a> -->
      <a href="#regular">Regular Transition Matrix</a>
      <a href="#non-regular">Non-Regular Transition Matrix</a>
      <a href="#steady-state">Steady-State Vectors</a>
      <a href="#eigen">Eigenvectors and Eigenvalues</a>
      <a href="second-iteration"Second Iteration</a>
      <a href="absorbing">Absorbing Markov Chains</a>
      <a href="applications">Applications</a>
      <a href=#repl>Markov Chains- Ruby Code</a>
      <a href=#sources>Sources</a>
    </nav>
    <div class="section-title" id="history">
      <h3>History</h3>
      <p>Markov chains are named after their creator, Andrey Markov. They are mathematical
        systems that anticipate future events from a current state. Markov initially designed Markov chains in order
        to analyze the frequencies of vowels and consonants in the novel<em> Eugene Onegin</em>.
        </p>
    </div>
    <div class="section-title" id="definition"><!--What is a Markov Chain?-->
      <h3>What is a Markov Chain?</center> </h3>
      <img src="resources/images/chain.png" align="left">
      <p>Markov Chains have a set of distinct states. They can be used to interpret and understand intricate, real-life processes.
      A fundamental aspect of Markov chains is its tendency to anticipate future states based on only its previous state.
      In other words, the outcomes of trials in the Markov Chains are dependent only on the outcome of the previous state. There can only be one state at a time. Each
      state gives a probability distribution of different events occuring. Because of this, more complex tasks are simplified and take into account a conditional probability
      instead of programs that involve countless of past scenarios.</p>
    </div>
    <div class="section-title" id="properties"><!--Properties of Markov Chains-->
      <h3>Properties of Markov Chains</center> </h3>
        <ul>
          <li>At any time, each object is at exactly one state</li>
          <li>Objects move between states according to transition probabilities (based on current state)</li>
          <li>Transition probabilities remain constant</li>
        </ul>
    </div>
    <div class="section-title" id="example"><!--Example of Markov Chain-->
      <h3>Example Problem</center> </h3>

      <p></p>
    </div>
    <div class="section-title" id="transition-matrix"><!--What does a Transition Matrix do?-->
      <h3>Transition Matrix</center> </h3>
      <p>Transition matrices contain all transition probabilities from one state to another.  </p>
    </div>
    <div class="section-title" id="transition-properties"><!--Properties of a Transition Matrix-->
      <h3>Properties of a Transition Matrix</center> </h3>
      <ul>
        <li>Must be a square matrix</li>
        <li>Elements represent probabilies, so these values must be in the range [0,1]</li>
        <li>The sum of all elements in a row must be 1</li>
        <li>Named T or P</li>
      </ul>
    </div>
    <div class="section-title" id="state-vectors"><!--State/Probability Vectors-->
      <h3>State/Probability Vectors</center> </h3>
      <p>For a system with <em>n</em> states, the <strong>state vector</strong> of a Markov chain
      is a row or column vector q^k of n elements where q is the probability that the system is in the ith state after
      k trials.</p>
    </div>
    <div class="section-title" id="state-vectors-properties">
      <h3>Properties of State Vectors</h3>
      <ul>
        <li>Horizontal vector</li>
        <li>Same number of elements as states in the Markov chain</li>
        <li>Shows probability distribution of all states</li>
        <li>Sum of elements is 1</li>
        <li>Named q or x</li>
      </ul>
    </div>
    <div class="section-title" id="regular">
      <h3>Regular Transition Matrix</h3>
      <p>
        Transition matrices are considered <em>regular</em> if they contain all non-zerp
        elements. These can be used to find steady-state or equilibrium vectors.
        <center><img src="resources/images/regular.PNG" Regular Transition Matrix/></center>
        <center>This matrix is regular because all of its elements are positive.</center>
      </p>
    </div>
    <div class="section-title" id="non-regular">
      <h3>Non-Regular Transition Matrix</h3>
      <p>
        Matrix A is not regular because any power of A still contains 0. Thus, no matrices of A contain
        all positive elements.
      </p>
      <center><img src="resources/images/nonregular.PNG" Non-Regular Transition Matrix/></center>
    </div>
    <div class="section-title" id="steady-state">
      <h3>Steady-State Vectors</h3>
      <p>
        After a large number of trials, the state vector remains constant. At this time, the
        Markov chain has reached a stable distribution. This is called the <em>steady-state vector</em>
        , also known as an <em>equilibrium vector</em>, and is represented by s or v. If A*p = A, then it is a steady-state vector.  <br>
        <strong>They are independent of the original probability distribution and remain constant no matter what.</strong>
      </p>
      <center><img src="resources/images/steady.PNG" Steady-state vector/></center>
    </div>
    <div class="section-title" id= "eigen">
      <h3>Eigenvectors and Eigenvalues</h3>

    </div>
    <div class="section-title" id="second-iteration">
      <h3>Second Iteration</h3>
      <p></p>
    </div>
    <div class="section-title" id="absorbing">
      <h3>Absorbing Markov Chains</h3>
      <p>
        When the probability of jumping from state A to state B is 0.5, the probability
        of staying at state A when it is already at state A is 1.
        This is called the absorbing state, since when it gets there, it gets "absorbed". At
        this point, it can no longer change to another state.
      </p>
    </div>





    <div class="section-title" id="repl">
      <h3> Markov Chains - Ruby Code </h3>
      <p>This is a demonstration of the workings of Markov Chains, coded with the
        programming language, Ruby. <br>To run this program, press the <em>run</em> button. Please do not alter any of the code.</p>
      <center><iframe frameborder="0" width="100%" height="500px" src="https://repl.it/GLmF/1"></iframe></center>
    </div>
    <div class="section-title" id="sources"><!--Sources-->
      <h3>Sources</h3>
        <a href="https://www.dartmouth.edu/~chance/teaching_aids/books_articles/probability_book/Chapter11.pdf">Click me</a><br>
        <a href="https://www.math.ucdavis.edu/~daddel/linear_algebra_appl/Applications/MarkovChain/MarkovChain_9_18/node1.html">Click me</a><br>
        <a href="https://www.scribd.com/document/338415365/DFAI-MARKOV-CHAINS-02-pdf">Click me</a>
        <a href="http://www.math.bas.bg/~jeni/Rebecca_Atherton.pdf">
    </div>




  </body>
</html>
